{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IT_018 DL Lab 25_03_2021.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3gNYXqc2kya",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ef6e68c3-5021-4ed7-da32-a02974952ede"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "Name : Aman Jha\n",
        "Lab : Deep Learning\n",
        "Date : 25-03-2021\n",
        "Title : Positive and Negative sentance classifier using random forest tree classifier\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nName : Aman Jha\\nLab : Deep Learning\\nDate : 25-03-2021\\nTitle : Positive and Negative sentance classifier using random forest tree classifier\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6lwYhM1tzK1",
        "outputId": "108b2046-88ad-4cd3-aaf7-8f79472e4a8e"
      },
      "source": [
        "import numpy as np, re, nltk, pickle\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwlM8r1iv4GQ"
      },
      "source": [
        "movie_data = load_files(\"/content/drive/MyDrive/Colab Notebooks/Classroom/positive and negative tweets\")\n",
        "\n",
        "X, y = movie_data.data, movie_data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkBlgAa0w3NW"
      },
      "source": [
        "# Text Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UArye6MSw12s"
      },
      "source": [
        "documents = []\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXe8yiuCxCEA",
        "outputId": "40ffa5bd-59ab-4f82-86af-8bb9a6288a3e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8jr9R1WxH0y"
      },
      "source": [
        "for sen in range(0, len(X)) :\n",
        "\n",
        "  document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "\n",
        "  document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "  document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "  document = re.sub(r'\\s+', ' ', document)\n",
        "\n",
        "  document = re.sub(r'b\\s+', '', document)\n",
        "\n",
        "  document = document.lower()\n",
        "\n",
        "  # Lemmatization\n",
        "  document = document.split()\n",
        "\n",
        "  document = [stemmer.lemmatize(word) for word in document]\n",
        "  document = ' '.join(document)\n",
        "\n",
        "  documents.append(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOM3qHTFyS0A"
      },
      "source": [
        "# Converting Text to Number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0zIhb4JyO4e"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features = 1500, min_df = 5, max_df = 0.7, stop_words = stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je9VwZmKzLGG",
        "outputId": "8cb412c4-f6c5-413e-92fc-7c287b57a60d"
      },
      "source": [
        "X[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C0Yeu5JzNBp"
      },
      "source": [
        "# Tf-IDf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRU3TWsNzOyp"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidfconverter = TfidfTransformer()\n",
        "\n",
        "X = tfidfconverter.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGD4D3bozd_o",
        "outputId": "671de407-7a3d-406f-8f4c-d0e2639219e1"
      },
      "source": [
        "X[7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , ..., 0.        , 0.04499071,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvHUBr4lzgQo"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words = stopwords.words('english'))\n",
        "X = tfidfconverter.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPayz8OJz8lq",
        "outputId": "94fe8c8e-0c54-43f0-eedc-772517630a97"
      },
      "source": [
        "X[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdiAY8hjz-vt"
      },
      "source": [
        "# Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEf-s5sg0Az6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po8W2Ast0Wo3",
        "outputId": "c32f7f91-90be-417d-c064-15e60d1297b3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators = 1000, random_state=0)\n",
        "classifier.fit(X_train, y_train) # Using Random Forest Classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbebIOCc0kBN"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK7JfBON0nme"
      },
      "source": [
        "# Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXTCEDd_0pQm",
        "outputId": "98351e36-40f0-4a74-98b4-53d1b8b0a673"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(\"Confusion Matrix:\", confusion_matrix(y_test,y_pred))\n",
        "print(\"Classification Report:\", classification_report(y_test,y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: [[181  24]\n",
            " [ 50 147]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       205\n",
            "           1       0.86      0.75      0.80       197\n",
            "\n",
            "    accuracy                           0.82       402\n",
            "   macro avg       0.82      0.81      0.81       402\n",
            "weighted avg       0.82      0.82      0.81       402\n",
            "\n",
            "Accuracy: 0.8159203980099502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwD9KWvJ1DMh"
      },
      "source": [
        "# Saving and Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0tIJAY21Cqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e766b2cf-5568-4841-b5f9-30bc4c52e57f"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/Classroom\"\n",
        "\n",
        "with open('text_classifier','wb') as picklefile :\n",
        "  pickle.dump(classifier,picklefile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Classroom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TlXkcbv1iVN"
      },
      "source": [
        "with open('text_classifier', 'rb') as training_model:\n",
        "  model = pickle.load(training_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez1DYeGi1uT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05d0289-d764-4f6f-d766-6414d281364c"
      },
      "source": [
        "y_pred2 = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred2))\n",
        "print(classification_report(y_test, y_pred2))\n",
        "print(accuracy_score(y_test, y_pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[181  24]\n",
            " [ 50 147]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       205\n",
            "           1       0.86      0.75      0.80       197\n",
            "\n",
            "    accuracy                           0.82       402\n",
            "   macro avg       0.82      0.81      0.81       402\n",
            "weighted avg       0.82      0.82      0.81       402\n",
            "\n",
            "0.8159203980099502\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}